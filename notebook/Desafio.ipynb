{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.functions as func\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caderno de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo DataFrames e Criando arquivos parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados= [(1, 3545, 3000, 6.99),\n",
    "    (2, 3545, 4500, 0.45),\n",
    "    (3,3509, 69998, 0.0),\n",
    "    (4, 3510, 1, None ),\n",
    "    (5, 4510, 34, 40.00)\n",
    "    ]\n",
    "\n",
    "schema = StructType([\\\n",
    "    StructField(\"transaction_id\", IntegerType(), True),\\\n",
    "    StructField(\"client_id\", IntegerType(), True),\\\n",
    "    StructField(\"total_amount\", IntegerType(), True),\\\n",
    "    StructField(\"discount_percentage\", FloatType())\\\n",
    "    ])\n",
    "\n",
    "Transacoes = spark.createDataFrame(data=dados, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados2 = [(3,3545, \"Magazine Luana\", 2.00, \"True\" ),\n",
    "    (4, 3545,\"Magazine Luana\", 1.95, \"False\"), \n",
    "    (5, 3509, \"Lojas Italianas\", 1.00, \"True\"),\n",
    "    (6, 3510, \"Carrerfive\", 3.00, \"True\")]\n",
    "    \n",
    "schema2 = StructType([\\\n",
    "    StructField(\"contract_id\", IntegerType(), True),\\\n",
    "    StructField(\"client_id\", IntegerType(), True),\\\n",
    "    StructField(\"client_name\", StringType(), True),\\\n",
    "    StructField(\"percentage\", FloatType(), True),\\\n",
    "    StructField(\"is_active\",StringType(),True)\n",
    "    ])\n",
    "contrato = spark.createDataFrame(data=dados2, schema=schema2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('contrato.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transacoes.write.parquet(\"transacoes.parquet/\")\n",
    "contrato.write.parquet(\"contrato.parquet/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|Fechamento|\n",
      "+----------+\n",
      "|    845.41|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def ganho_total(transacao, contrato):\n",
    "    desafio = contrato.join(Transacoes, contrato.client_id == Transacoes.client_id, 'left')\\\n",
    "        .filter(contrato.is_active == True)\\\n",
    "        .select(func.round(sum((col('total_amount')-(col('total_amount')*coalesce(col('discount_percentage'),lit(0.0))/100))*col('percentage'))/100,2).alias('mes')\\\n",
    "        .alias('Fechamento'))\n",
    "    desafio.write.parquet('/home/desafio3.parquet/')\n",
    "    return desafio\n",
    "    \n",
    "ganho_total(Transacoes, contrato)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyspark com SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transacoes.createOrReplaceTempView('Transacoes')\n",
    "contrato.createOrReplaceTempView('contrato')\n",
    "Transacoes.show()\n",
    "contrato.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|   Mes|\n",
      "+------+\n",
      "|845.41|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teste3 = spark.sql('''\n",
    "    select\n",
    "        round(sum((T.total_amount-((T.total_amount*coalesce(T.discount_percentage,0)) / 100)) * (c.percentage) / 100),2) as Mes  \n",
    "    from \n",
    "        contrato as c\n",
    "        left join Transacoes as T on c.client_id = T.client_id\n",
    "    where is_active = 'True'\n",
    "    ''')\n",
    "teste3.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3fd8f61f8f54ff0cae9a83bb813d9d5683b3c3fa7f3560094c24f7445c0d4f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
